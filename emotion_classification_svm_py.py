# -*- coding: utf-8 -*-
"""Emotion_Classification_SVM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TGOp2GKtwbe6sFBMJwkqi5iIQ-TOzxtS

### Import necessary libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, f1_score)
from sklearn.svm import SVC
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import GridSearchCV
import re
import json
from collections import defaultdict
import time

"""### Load the dataset and Display basic information


"""

df = pd.read_csv('/content/test.csv')
df.head()

print("\nDataset Info:")
print(df.info())

print("\nFirst 5 rows:")
print(df.head())

print("\nDataset Description:")
print(df.describe(include='all'))

print("\nClass Distribution:")
print(df['label'].value_counts())

"""### Visualize class distribution

"""

# Visualize class distribution
plt.figure(figsize=(8, 4))
sns.countplot(data=df, x='label')
plt.title('Distribution of Emotion Labels')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""### Data Preprocessing

"""

print("\nPreprocessing the data...")

# Check for missing values
print("\nMissing values:")
print(df.isnull().sum())

"""## Feature Extraction"""

print("\nExtracting features using TF-IDF...")

# Initialize TF-IDF Vectorizer with improved parameters
tfidf = TfidfVectorizer(
    stop_words='english',
    max_features=5000,
    ngram_range=(1, 2),  # Consider unigrams and bigrams
    min_df=5,            # Ignore terms that appear in fewer than 5 documents
    max_df=0.7           # Ignore terms that appear in more than 70% of documents
)

# Fit and transform the 'text' column
X = tfidf.fit_transform(df['text'])
y = df['label']

print(f"\nShape of feature matrix: {X.shape}")

"""### Split data into train and test sets

"""

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y  # Maintain class distribution in splits
)

print(f"\nTrain set size: {X_train.shape[0]}")
print(f"Test set size: {X_test.shape[0]}")

"""##Model Training - Baseline SVM"""

print("\nTraining baseline SVM model...")

# Train baseline SVM
svm_baseline = SVC(kernel='linear', C=1.0, class_weight='balanced', random_state=42)
svm_baseline.fit(X_train, y_train)

"""## Predict on test data

"""

#Predict on test data
y_pred = svm_baseline.predict(X_test)

# Evaluate baseline model
print("\nBaseline Model Performance:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

"""##Plot confusion matrix

"""

#Plot confusion matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=le.classes_ if 'le' in locals() else np.unique(y),
            yticklabels=le.classes_ if 'le' in locals() else np.unique(y))
plt.title('Confusion Matrix for Baseline SVM Model')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.tight_layout()
plt.show()

"""## Hyperparameter Tuning for Improved Accuracy"""

print("\nPerforming hyperparameter tuning to improve accuracy...")

# Define parameter grid
param_grid = {
    'C': [0.1, 1, 10, 100],
    'kernel': ['linear', 'rbf'],
    'gamma': ['scale', 'auto']
}

# Initialize GridSearchCV
grid_search = GridSearchCV(
    SVC(class_weight='balanced', random_state=42),
    param_grid,
    cv=5,
    n_jobs=-1,
    verbose=1
)

# Perform grid search
print("\nStarting grid search...")
grid_search.fit(X_train, y_train)

# Get best parameters
print("\nBest parameters found:")
print(grid_search.best_params_)

# Train model with best parameters
best_svm = grid_search.best_estimator_
y_pred_tuned = best_svm.predict(X_test)

# Evaluate tuned model
print("\nTuned Model Performance:")
print("Accuracy:", accuracy_score(y_test, y_pred_tuned))
print("\nClassification Report:\n", classification_report(y_test, y_pred_tuned))

"""### Plot confusion matrix for tuned model

"""

# Plot confusion matrix for tuned model
cm_tuned = confusion_matrix(y_test, y_pred_tuned)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_tuned, annot=True, fmt='d', cmap='Greens',
            xticklabels=le.classes_ if 'le' in locals() else np.unique(y),
            yticklabels=le.classes_ if 'le' in locals() else np.unique(y))
plt.title('Confusion Matrix for Tuned SVM Model')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.tight_layout()
plt.show()

"""## Alert System"""

class EmotionAlertSystem:
    def __init__(self, model, vectorizer, label_encoder=None, alert_rules=None):
        self.model = model
        self.vectorizer = vectorizer
        self.label_encoder = label_encoder
        self.alert_rules = alert_rules or {
            'high_risk': [3, 4],  # Assuming anger=3, fear=4
            'medium_risk': [2],    # sadness=2
            'threshold': 0.6       # Lower confidence threshold
}
        self.alert_history = defaultdict(list)

    def decode_label(self, label):
        """Convert encoded label back to original"""
        if self.label_encoder:
            return self.label_encoder.inverse_transform([label])[0]
        return label

    def check_for_alerts(self, text):
        """Analyze text and trigger alerts if needed"""
        if isinstance(text, str):
            text = [text]

        features = self.vectorizer.transform(text)
        predictions = self.model.predict(features)
        probabilities = self.model.predict_proba(features)
        confidences = np.max(probabilities, axis=1)

        results = []
        for i, (pred, conf) in enumerate(zip(predictions, confidences)):
            emotion = self.decode_label(pred)
            result = {
                'text': text[i],
                'emotion': emotion,
                'confidence': float(conf),
                'alert': None,
                'timestamp': time.time()
            }

            # Check alert rules
            if conf >= self.alert_rules['threshold']:
                if emotion in self.alert_rules['high_risk']:
                    result['alert'] = 'HIGH_RISK'
                    self.alert_history['high_risk'].append(result)
                elif emotion in self.alert_rules['medium_risk']:
                    result['alert'] = 'MEDIUM_RISK'
                    self.alert_history['medium_risk'].append(result)

            results.append(result)

        return results

    def get_recent_alerts(self, alert_type=None, limit=5):
        """Retrieve recent alerts"""
        if alert_type:
            return self.alert_history.get(alert_type, [])[:limit]
        return {k: v[:limit] for k, v in self.alert_history.items()}

# Define the missing functions
def load_and_preprocess_data(filepath):
    """Loads data, handles missing values, and encodes labels."""
    df = pd.read_csv(filepath)
    # Assuming no missing values based on the initial check

    # Label Encoding
    le = LabelEncoder()
    # Fit on the entire 'label' column to ensure all possible labels are encoded
    le.fit(df['label'])
    df['label_encoded'] = le.transform(df['label'])

    return df, le

def create_features(df):
    """Creates TF-IDF features from the text data."""
    tfidf = TfidfVectorizer(
        stop_words='english',
        max_features=5000,
        ngram_range=(1, 2),
        min_df=5,
        max_df=0.7
    )
    X = tfidf.fit_transform(df['text'])
    # Use the encoded labels
    y = df['label_encoded']
    return X, y, tfidf

def train_evaluate_model(X_train, X_test, y_train, y_test, kernel='linear'):
    """Trains an SVM model and evaluates it."""
    model = SVC(kernel=kernel, C=1.0, class_weight='balanced', random_state=42, probability=True) # probability=True needed for predict_proba in AlertSystem
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    print(f"Evaluation for {kernel} kernel:")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("\nClassification Report:\n", classification_report(y_test, y_pred))
    print("-" * 30)

    return model

"""## Main Execution"""

def main():
    # Load data
    print("Loading and preprocessing data...")
    df, le = load_and_preprocess_data('/content/test.csv')

    # Create features
    X, y, tfidf = create_features(df)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # Train and evaluate models with different kernels
    kernels = ['linear', 'rbf', 'poly']
    models = {}

    for kernel in kernels:
        print(f"\nTraining model with {kernel} kernel...")
        model = train_evaluate_model(X_train, X_test, y_train, y_test, kernel)
        models[kernel] = model

    # Select best model (here we choose based on F1 score)
    best_model = models['linear']  # Typically linear works best for text

    # Initialize alert system
    alert_system = EmotionAlertSystem(best_model, tfidf, le, {
        'high_risk': ['anger', 'fear'],
        'medium_risk': ['sadness'],
        'threshold': 0.75
    })

    # Demo predictions with alerts
    test_tweets = [
        "I'm so angry about what happened today! This is unacceptable!",
        "Feeling really anxious about the upcoming events...",
        "So happy to see you all! Let's celebrate!",
        "The situation is getting worse. I'm scared.",
        "Just feeling a bit sad today, nothing serious."
    ]

    print("\nTesting alert system with sample tweets:")
    for tweet in test_tweets:
        results = alert_system.check_for_alerts(tweet)
        for res in results:
            print(f"\nTweet: {res['text']}")
            print(f"Emotion: {res['emotion']} (Confidence: {res['confidence']:.2f})")
            if res['alert']:
                print(f"ðŸš¨ ALERT TRIGGERED: {res['alert']}")
            else:
                print("No alert triggered")

    # Save model components for deployment
    import joblib
    joblib.dump({
        'model': best_model,
        'vectorizer': tfidf,
        'label_encoder': le,
        'alert_rules': alert_system.alert_rules
    }, 'emotion_classifier.pkl')

    print("\nModel and alert system saved to 'emotion_classifier.pkl'")

if __name__ == '__main__':
    main()